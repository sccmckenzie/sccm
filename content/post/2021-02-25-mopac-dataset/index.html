---
title: Crafting an Artificial Dataset
author: Scott McKenzie
date: '2021-02-25'
slug: mopac-dataset
categories: []
tags:
  - R
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>In this post, I explain how I simulated vehicle records for the <a href="https://www.mobilityauthority.com/traveler-info/open-roads/MoPac-Express">Mopac Express Lane</a> in Austin, Texas.</p>
<p><img src="mopac-birds-eye.jpg" /></p>
<div id="motivation" class="section level1">
<h1>Motivation</h1>
<p>I am currently working towards the release of my second R package, <a href="https://github.com/sccmckenzie/sift">sift</a>. This package is essentially an amalgam of various ideas Iâ€™ve had over the past few years. Since grouping these ideas into one package was very important to me, I needed a common theme to tie all of the functions together.</p>
<p>The dataset created in this post, <strong><code>express</code></strong>, serves as a realistic case study where one can effectively utilize the full capability of <a href="https://github.com/sccmckenzie/sift">sift</a>.</p>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(jsonlite)

options(readr.default_locale = locale(tz = &quot;US/Central&quot;))
theme_set(theme_minimal())</code></pre>
</div>
<div id="step-1-reconnaissance" class="section level1">
<h1>Step 1: Reconnaissance</h1>
<p>How frequent are various vehicle types on Mopac? Lots of F-150s? Toyota Camrys?</p>
<p>By no means does the intended application of the dataset require 100% accuracy. However, achieving something somewhat realistic was still important to me. After coming up dry on Google, I decided to walk out my front door and get the answer from the primary source.</p>
<p>Discreetly nestled in a grove overlooking Mopac, I aimed my camera at rush hour traffic and let the shutter snap for 2.5 minutes. After repeating this over the course of 1 week, I had collected over 600 frames.</p>
<p><img src="mopac-collage.png" /></p>
<p>These photos present a clear opportunity to apply an Image Recognition ML algorithm - but Iâ€™m saving that for a future post. ðŸ˜‰</p>
<p>The resulting dataset is named <strong><code>rush_hour</code>.</strong></p>
<pre class="r"><code>rush_hour &lt;- read_csv(&quot;https://raw.githubusercontent.com/sccmckenzie/mopac/master/inst/extdata/rush_hour.csv&quot;)
# also available in mopac::rush_hour

rush_hour %&gt;% 
  sample_n(5) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">day</th>
<th align="left">time</th>
<th align="left">commercial</th>
<th align="left">color</th>
<th align="left">type</th>
<th align="left">make</th>
<th align="left">model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Fri</td>
<td align="left">2020-05-22 18:46:33</td>
<td align="left">FALSE</td>
<td align="left">Blue</td>
<td align="left">Hatch</td>
<td align="left">Toyota</td>
<td align="left">Prius</td>
</tr>
<tr class="even">
<td align="left">Sun</td>
<td align="left">2020-05-17 17:27:51</td>
<td align="left">FALSE</td>
<td align="left">Blue</td>
<td align="left">Hatch</td>
<td align="left">Nissan</td>
<td align="left">Versa</td>
</tr>
<tr class="odd">
<td align="left">Tue</td>
<td align="left">2020-05-19 18:42:14</td>
<td align="left">TRUE</td>
<td align="left">Grey</td>
<td align="left">Truck</td>
<td align="left">Dodge</td>
<td align="left">Ram</td>
</tr>
<tr class="even">
<td align="left">Sat</td>
<td align="left">2020-05-23 15:07:10</td>
<td align="left">FALSE</td>
<td align="left">Black</td>
<td align="left">SUV</td>
<td align="left">Mazda</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left">Wed</td>
<td align="left">2020-05-20 18:29:01</td>
<td align="left">FALSE</td>
<td align="left">Silver</td>
<td align="left">Hatch</td>
<td align="left">Toyota</td>
<td align="left">Prius</td>
</tr>
</tbody>
</table>
<p>If you live in Texas, the below results shouldnâ€™t come as a surprise.</p>
<pre class="r"><code>rush_hour %&gt;% 
  unite(make_model, make, model, sep = &quot; &quot;) %&gt;% 
  drop_na(make_model) %&gt;% 
  count(make_model) %&gt;% 
  slice_max(order_by = n, n = 10) %&gt;% 
  ggplot(aes(n, fct_reorder(make_model, n))) +
  geom_col()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Although <strong><code>rush_hour</code></strong> satisfies the need for realistic vehicle make/model frequencies, it cannot serve as a basis for inferring express lane traffic density since observations were obtained from Mopac mainlanes.</p>
<p>To avoid further speculation, I made another trip to acquire express lane timestamps (collected during afternoon rush hour).</p>
<pre class="r"><code>express_counts &lt;- read_csv(&quot;https://raw.githubusercontent.com/sccmckenzie/mopac/master/inst/extdata/express_counts.csv&quot;)

glimpse(express_counts)</code></pre>
<pre><code>## Rows: 250
## Columns: 1
## $ time &lt;dttm&gt; 2021-03-04 17:57:16, 2021-03-04 17:57:18, 2021-03-04 17:57:22...</code></pre>
</div>
<div id="step-2-defining-scope" class="section level1">
<h1>Step 2: Defining Scope</h1>
<p>Mopac contains an express lane stretching 11 miles between downtown Austin to Parmer Lane. There is an intermediate access point near RM 2222, boxed in <span style="color: #ff00ff;">pink</span> below.</p>
<div style="width: 396px; margin-left: auto; margin-right: auto;">
<p><img src = "express-lane-map.png" /></p>
</div>
<ul>
<li>Our mock dataset, <strong><code>express</code></strong>, will feature vehicle descriptions + timestamps <strong>as if they are captured at the RM 2222 checkpoint,</strong></li>
<li>Weâ€™ll obtain peak traffic distribution by bootstrapping <strong><code>express_counts</code></strong>, then adjusting based on City of Austin data.</li>
<li>Vehicle make/model/color frequencies will be inferred from <strong><code>rush_hour</code></strong>.[^1]</li>
</ul>
</div>
<div id="step-3-peak-traffic-distribution" class="section level1">
<h1>Step 3: Peak Traffic Distribution</h1>
<p>First, we extract timestamp spacing from <strong><code>express_counts</code></strong>.</p>
<pre class="r"><code>set.seed(10)
t_delta &lt;- express_counts %&gt;%
  mutate(t_delta = time_length(time - lag(time))) %&gt;%
  drop_na(t_delta) %&gt;%
  mutate(t_delta = t_delta + 2 * rbeta(n(), 2, 3)) %&gt;%
  # ^ we add some jitter into timestamps
  # (observations were recorded with 1 sec resolution)
  pull(t_delta)

t_delta %&gt;% 
  qplot(binwidth = 0.25) # histogram</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>To simulate timestamps for <strong><code>express</code></strong>, we perform bootstrap sampling from the above distribution.</p>
<pre class="r"><code># set timeframe (5am - 8pm)
t1 &lt;- 5 
t2 &lt;- 20
total_seconds &lt;- (t2 - t1) * 3600

set.seed(20)
express &lt;- tibble(direction = c(&quot;North&quot;, &quot;South&quot;)) %&gt;%
  rowwise(direction) %&gt;%
  summarize(vehicle_spacing = sample(t_delta, size = total_seconds, replace = TRUE)) %&gt;%
  # ^ generate temporal vehicle spacing
  transmute(time = make_datetime(2020, 5, 20, t1, tz = &quot;US/Central&quot;) + cumsum(vehicle_spacing)) %&gt;% 
    # ^ add temporal vehicle spacing together
  filter(time &lt; make_datetime(2020, 5, 20, t2, tz = &quot;US/Central&quot;))
# ^ cut off timestamps later than 8pm

express %&gt;%
  group_by(direction,
           t15 = floor_date(time, unit = &quot;15 minutes&quot;)) %&gt;% 
  summarize(volume = n()) %&gt;% 
  ggplot(aes(t15, volume)) +
  geom_line(aes(color = direction))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>While we have achieved some randomness, the consistent baseline around 150 is unrealistic. For example, around 6:00am, nobody is <em>actually</em> using the express lane.</p>
</div>
<div id="step-4-exploring-city-of-austin-api" class="section level1">
<h1>Step 4: Exploring City of Austin API</h1>
<p>Although Texas state highway traffic count data is elusive (at least at the granularity needed for this application), the City of Austin (COA) provides ample resources on frontage road intersections.</p>
<p>Below we access Mopac &amp; Steck Ave traffic volume measurements from COA open data portal. This intersection is located ~ 3mi north of Mopac &amp; RM 2222, which unfortunately doesnâ€™t have records in the <a href="https://data.austintexas.gov/Transportation-and-Mobility/Camera-Traffic-Counts/sh59-i6y9">Camera Traffic Counts</a> table.</p>
<pre class="r"><code>steck &lt;- jsonlite::fromJSON(&#39;https://data.austintexas.gov/resource/sh59-i6y9.json?atd_device_id=6409&amp;year=2020&amp;month=5&amp;day=20&amp;heavy_vehicle=false&#39;) %&gt;% 
  as_tibble() %&gt;% 
  janitor::clean_names() %&gt;% 
  transmute(read_date = as_datetime(read_date, tz = &quot;US/Central&quot;),
            direction,
            movement,
            volume = as.integer(volume))</code></pre>
<p>Each row contains measurements summarized over 15 minutes intervals.</p>
<pre class="r"><code>steck %&gt;% 
  sample_n(5) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">read_date</th>
<th align="left">direction</th>
<th align="left">movement</th>
<th align="right">volume</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2020-05-20 00:45:00</td>
<td align="left">EASTBOUND</td>
<td align="left">RIGHT TURN</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">2020-05-20 07:15:00</td>
<td align="left">NORTHBOUND</td>
<td align="left">THRU</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="left">2020-05-20 10:30:00</td>
<td align="left">NORTHBOUND</td>
<td align="left">LEFT TURN</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left">2020-05-20 01:00:00</td>
<td align="left">SOUTHBOUND</td>
<td align="left">LEFT TURN</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">2020-05-20 22:00:00</td>
<td align="left">SOUTHBOUND</td>
<td align="left">THRU</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p>Here, we restrict our focus to north &amp; south, as these are the only directions that could correspond to cars entering Mopac.</p>
<pre class="r"><code>steck %&gt;% 
  filter(direction %in% c(&quot;NORTHBOUND&quot;, &quot;SOUTHBOUND&quot;)) %&gt;%
  group_by(direction, read_date) %&gt;% 
  summarize(volume = sum(volume)) %&gt;% 
  ggplot(aes(read_date, volume)) +
  geom_line(aes(color = direction))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>The above distribution is much more believable: starting around 6am, traffic increases, levels out, gets worse around lunch, and finally recedes after 6pm.</p>
<p>The large discrepancy between north &amp; south may be due to the fact that itâ€™s extremely difficult to get on northbound Mopac from Steck Ave. In other words, people may be opting for an alternate access point if they are travelling north.</p>
<p>For the sake of simplicity, we will project the SOUTHBOUND distribution onto our <strong><code>express</code></strong> dataset (both directions).</p>
<pre class="r"><code>steck_normalized &lt;- steck %&gt;% 
  filter(direction == &quot;SOUTHBOUND&quot;) %&gt;% 
  with_groups(read_date,
              summarize,
              volume = sum(volume)) %&gt;% 
  transmute(id = row_number(),
            read_date,
            volume = volume/max(volume))

set.seed(25)

# join Steck volume with express timestamps
express &lt;- express %&gt;% 
  mutate(id = findInterval(time, steck_normalized$read_date)) %&gt;% 
  left_join(steck_normalized, by = &quot;id&quot;) %&gt;% 
  rowwise() %&gt;% 
  mutate(keep = sample(c(FALSE, TRUE), prob = c(1 - volume, volume), size = 1)) %&gt;% 
  # ^ treat volume as probability of keeping row in express
  ungroup() %&gt;% 
  filter(keep) %&gt;% 
  select(direction, time) %&gt;% 
  arrange_all()

express %&gt;%
  group_by(direction,
           t15 = floor_date(time, unit = &quot;15 minutes&quot;)) %&gt;% 
  summarize(volume = n()) %&gt;% 
  ggplot(aes(t15, volume)) +
  geom_line(aes(color = direction))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Voila! Admittedly, this is a somewhat hackish method to achieve the desired result. For the intended purpose of this dataset, we donâ€™t need to worry about using more sophisticated statistical techniques.</p>
</div>
<div id="step-5-trip-modeling" class="section level1">
<h1>Step 5: Trip Modeling</h1>
<p>Though we could arbitrarily assign a unique vehicle for each row in <strong><code>express</code></strong>, this wouldnâ€™t be realistic. Consider the below scenarios:</p>
<ol style="list-style-type: decimal">
<li>Vehicle uses Express Lane once <strong>in one direction</strong>.</li>
<li>Vehicle uses Express Lane once <strong>in both directions</strong> (e.g.Â commuting to &amp; from work).</li>
<li>Vehicle uses Express Lane thrice <strong>in any combination of directions</strong> (e.g.Â rideshare).</li>
</ol>
<p>Before we jump in, letâ€™s create a helper to extract hour of day as a decimal. This will improve readability of our downstream code.</p>
<pre class="r"><code>hourday &lt;- function(t) {
  time_length(t - make_datetime(2020, 5, 20, tz = &quot;US/Central&quot;), unit = &quot;hours&quot;)
}

# example
hourday(as_datetime(&quot;2020-05-20 12:30:00&quot;, tz = &quot;US/Central&quot;))</code></pre>
<pre><code>## [1] 12.5</code></pre>
<p>For Scenario #1, each vehicle corresponds to one timestamp. Weâ€™ll obtain 5000 observations using a single unbiased sample.</p>
<pre class="r"><code>set.seed(254)
scenario_1 &lt;- express %&gt;% 
  sample_n(size = 5000) %&gt;% 
  mutate(v_id = row_number())

scenario_1 %&gt;% 
  ggplot(aes(time)) + 
  geom_histogram(aes(fill = direction), binwidth = 900)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Note the above distribution contains roughly the same amount of north &amp; south observations. For Scenario 2, weâ€™ll need to enforce actual equality between directions so that each north timestamps has a corresponding south timestamp.</p>
<p>Each vehicle will contain 2 timestamps:</p>
<ul>
<li>Timestamp A (driving to work)</li>
<li>Timestamp B (driving home)</li>
</ul>
<p>We sample <strong>A</strong> Timestamps weighted by <span class="math inline">\(\mathcal{N}(7\textrm{am}, 4\textrm{hr})\)</span>.</p>
<pre class="r"><code>set.seed(400)
scenario_2A &lt;- express %&gt;% 
  anti_join(scenario_1) %&gt;%
  # ^ exclude observations already sampled into scenario_1
  group_by(direction) %&gt;% 
  # ^ need equal amounts of north &amp; south samples
  sample_n(size = 1000, weight = dnorm(hourday(time), mean = 7, sd = 2)) %&gt;% 
  mutate(id = row_number()) %&gt;% 
  ungroup()</code></pre>
<p>Weâ€™ll assume most trips take ~10 hours (9 hour workday + 30 minute commute each way). This implies a <strong>B</strong> timestamp distribution of <span class="math inline">\(\mathcal{N}(5\textrm{pm}, 4\textrm{hr})\)</span>.</p>
<pre class="r"><code>scenario_2B &lt;- express %&gt;% 
  anti_join(scenario_1) %&gt;%
  anti_join(scenario_2A) %&gt;% 
  group_by(direction) %&gt;% 
  sample_n(size = 1000, weight = dnorm(hourday(time), mean = 17, sd = 2)) %&gt;% 
  mutate(id = row_number()) %&gt;% 
  ungroup()

bind_rows(
  mutate(scenario_2A, grp = &quot;A&quot;), 
  mutate(scenario_2B, grp = &quot;B&quot;)
  ) %&gt;% 
  ggplot(aes(time)) +
  geom_histogram(aes(fill = grp))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Notice there is some overlap between the A &amp; B distribution. This is intentional, as there will inevitably be some drivers that start their commute in the afternoon.</p>
<p>Currently, there are no unique vehicles tying observations together between <strong><code>scenario_2A</code></strong> &amp; <strong><code>scenario_2B</code></strong>. At first, I tried using for-loop structure - but this was excessively slow. After some brainstorming, I came up with the below procedure, which avoids for-loops entirely!</p>
<ol style="list-style-type: decimal">
<li>Randomly create multiple sets of timestamp pairs (only pairing opposite directions together).</li>
<li>Eliminate sets that contain impossible pairs (e.g.Â negative trip length).</li>
<li>Examine trip length distributions and select set that appears normal.</li>
</ol>
<pre class="r"><code># I arbitrarily set the number of repetitions to 100,
# which is ultimately more than enough to achieve desired result
scenario_2_sim &lt;- bind_rows(
  map_dfr(1:100, ~ {
  tibble(i = ..1,
         direction = &quot;NS&quot;,
         North = filter(scenario_2A, direction == &quot;North&quot;)$time %&gt;% sample(),
         South = filter(scenario_2B, direction == &quot;South&quot;)$time %&gt;% sample())
    # ^ for a given set, each timestamp only appears once
  }),
  map_dfr(1:100, ~ {
  tibble(i = ..1,
         direction = &quot;SN&quot;,
         South = filter(scenario_2A, direction == &quot;South&quot;)$time %&gt;% sample(),
         North = filter(scenario_2B, direction == &quot;North&quot;)$time %&gt;% sample())
    # ^ same thing as above, except now we flip the directions
  })
) %&gt;% 
  mutate(l = if_else(direction == &quot;NS&quot;,
                     time_length(South - North, unit = &quot;hours&quot;),
                     time_length(North - South, unit = &quot;hours&quot;))) %&gt;% 
  with_groups(c(direction, i), filter, !any(l &lt; 0.5))
# ^ a complete circuit around the express lane would take at least 1/2 an hour
  
scenario_2_sim %&gt;% 
  ggplot(aes(l)) +
  geom_density(aes(color = factor(i))) +
  facet_wrap(~ direction, ncol = 1)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Most of these distributions appear normal. Weâ€™ll pick the one with the highest Shapiro-Wilk normality test statistic.</p>
<pre class="r"><code>library(broom)

scenario_2 &lt;- scenario_2_sim %&gt;% 
  group_by(direction, i) %&gt;% 
  summarize(vec = list(l)) %&gt;% 
  rowwise() %&gt;% 
  mutate(shapiro.test(vec) %&gt;% tidy()) %&gt;% 
  filter(p.value &lt; 0.1) %&gt;% 
  group_by(direction) %&gt;% 
  slice_max(order_by = statistic) %&gt;% 
  semi_join(scenario_2_sim, .) %&gt;% 
  transmute(North, South, v_id = max(scenario_1$v_id) + row_number()) %&gt;% 
  pivot_longer(North:South, names_to = &quot;direction&quot;, values_to = &quot;time&quot;)</code></pre>
<p>For Scenario 3, we wonâ€™t impose any distributional or directional constraints on timestamp selection.</p>
<pre class="r"><code>scenario_3 &lt;- express %&gt;% 
  anti_join(scenario_1) %&gt;% 
  anti_join(scenario_2) %&gt;% 
  sample_n(size = n()) %&gt;% 
  mutate(v_id = (row_number() - 1) %% 3 == 0,
         v_id = cumsum(v_id) + max(scenario_2$v_id)) %&gt;% 
  group_by(v_id) %&gt;% 
  arrange(v_id, time) %&gt;% 
  mutate(delta = time_length(time - lag(time), unit = &quot;hours&quot;)) %&gt;% 
  filter(!any(delta &lt; 1, na.rm = TRUE)) %&gt;% 
  ungroup() %&gt;% 
  slice_head(n = 300) %&gt;% 
  select(direction, time, v_id)</code></pre>
<!-- ```{r} -->
<!-- express %>% -->
<!--   anti_join(scenario_1) %>% -->
<!--   anti_join(scenario_2) %>% -->
<!--   anti_join(scenario_3) %>% -->
<!--   ggplot(aes(time)) + -->
<!--   geom_histogram(aes(fill = direction)) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- express %>% -->
<!--   anti_join(scenario_1) %>% -->
<!--   anti_join(scenario_2) %>% -->
<!--   anti_join(scenario_3) -->
<!-- ``` -->
</div>
